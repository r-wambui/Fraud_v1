{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "      <th>attributed_time</th>\n",
       "      <th>is_attributed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83230</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:32:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17357</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:33:34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35810</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:34:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45745</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>478</td>\n",
       "      <td>2017-11-06 14:34:52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161007</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:35:08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ip  app  device  os  channel           click_time attributed_time  \\\n",
       "0   83230    3       1  13      379  2017-11-06 14:32:21             NaN   \n",
       "1   17357    3       1  19      379  2017-11-06 14:33:34             NaN   \n",
       "2   35810    3       1  13      379  2017-11-06 14:34:12             NaN   \n",
       "3   45745   14       1  13      478  2017-11-06 14:34:52             NaN   \n",
       "4  161007    3       1  13      379  2017-11-06 14:35:08             NaN   \n",
       "\n",
       "   is_attributed  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\", nrows=1000000)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18790469"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "test_df.head()\n",
    "test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "class FraudDataset(Dataset):\n",
    "    def __init__(self, dataset, train=True):\n",
    "        self.dataset = dataset\n",
    "        self.train = train\n",
    "        if self.train:\n",
    "            self.train_features = self.dataset.iloc[:, 1:5]\n",
    "            self.train_label = self.dataset.iloc[:, 7]\n",
    "        else:\n",
    "            self.train_features = self.dataset.iloc[:, 2:6]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            # x_train=features and y_train=labels\n",
    "            x_train, y_train = self.train_features.iloc[index],  self.train_label.iloc[index]\n",
    "            x_train = x_train.to_dict()\n",
    "            a = tuple(x_train.values())\n",
    "            a = torch.Tensor(a)\n",
    "\n",
    "            return a, y_train\n",
    "        else:\n",
    "            x_train = self.train_features.iloc[index]\n",
    "            x_train = x_train.to_dict()\n",
    "            a = tuple(x_train.values())\n",
    "            a = torch.Tensor(a)\n",
    "            \n",
    "            return a\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18790469\n"
     ]
    }
   ],
   "source": [
    "data = FraudDataset(test_df, train=False) \n",
    "a = data.__len__()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the train data\n",
    "train_data = FraudDataset(train_df)\n",
    "test_data = FraudDataset(test_df, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data loader\n",
    "batch_size = 128\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if loder is iterablle\n",
    "import collections\n",
    "isinstance(train_loader, collections.Iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_features, output_labels):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_features, output_labels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/20],  Loss: 7.5065\n",
      "Epoch: [1/20],  Loss: 7.3989\n",
      "Epoch: [1/20],  Loss: 7.9319\n",
      "Epoch: [1/20],  Loss: 7.7962\n",
      "Epoch: [1/20],  Loss: 8.2628\n",
      "Epoch: [1/20],  Loss: 7.9650\n",
      "Epoch: [1/20],  Loss: 7.7739\n",
      "Epoch: [2/20],  Loss: 8.0245\n",
      "Epoch: [2/20],  Loss: 7.6734\n",
      "Epoch: [2/20],  Loss: 7.7821\n",
      "Epoch: [2/20],  Loss: 7.6990\n",
      "Epoch: [2/20],  Loss: 7.6815\n",
      "Epoch: [2/20],  Loss: 7.7207\n",
      "Epoch: [2/20],  Loss: 7.8538\n",
      "Epoch: [3/20],  Loss: 7.8429\n",
      "Epoch: [3/20],  Loss: 7.9278\n",
      "Epoch: [3/20],  Loss: 7.9054\n",
      "Epoch: [3/20],  Loss: 7.9489\n",
      "Epoch: [3/20],  Loss: 7.8753\n",
      "Epoch: [3/20],  Loss: 7.8539\n",
      "Epoch: [3/20],  Loss: 7.7840\n",
      "Epoch: [4/20],  Loss: 7.8197\n",
      "Epoch: [4/20],  Loss: 7.8281\n",
      "Epoch: [4/20],  Loss: 7.9183\n",
      "Epoch: [4/20],  Loss: 7.8251\n",
      "Epoch: [4/20],  Loss: 7.8128\n",
      "Epoch: [4/20],  Loss: 7.7796\n",
      "Epoch: [4/20],  Loss: 7.7492\n",
      "Epoch: [5/20],  Loss: 7.7246\n",
      "Epoch: [5/20],  Loss: 7.7664\n",
      "Epoch: [5/20],  Loss: 7.7492\n",
      "Epoch: [5/20],  Loss: 7.8194\n",
      "Epoch: [5/20],  Loss: 7.7914\n",
      "Epoch: [5/20],  Loss: 7.7662\n",
      "Epoch: [5/20],  Loss: 7.7206\n",
      "Epoch: [6/20],  Loss: 7.7324\n",
      "Epoch: [6/20],  Loss: 7.7212\n",
      "Epoch: [6/20],  Loss: 7.7338\n",
      "Epoch: [6/20],  Loss: 7.7660\n",
      "Epoch: [6/20],  Loss: 7.7024\n",
      "Epoch: [6/20],  Loss: 7.7590\n",
      "Epoch: [6/20],  Loss: 7.7587\n",
      "Epoch: [7/20],  Loss: 7.7187\n",
      "Epoch: [7/20],  Loss: 7.6950\n",
      "Epoch: [7/20],  Loss: 7.7117\n",
      "Epoch: [7/20],  Loss: 7.6997\n",
      "Epoch: [7/20],  Loss: 7.7217\n",
      "Epoch: [7/20],  Loss: 7.7455\n",
      "Epoch: [7/20],  Loss: 7.7005\n",
      "Epoch: [8/20],  Loss: 7.6985\n",
      "Epoch: [8/20],  Loss: 7.6824\n",
      "Epoch: [8/20],  Loss: 7.6743\n",
      "Epoch: [8/20],  Loss: 7.6673\n",
      "Epoch: [8/20],  Loss: 7.6936\n",
      "Epoch: [8/20],  Loss: 7.6966\n",
      "Epoch: [8/20],  Loss: 7.6737\n",
      "Epoch: [9/20],  Loss: 7.6891\n",
      "Epoch: [9/20],  Loss: 7.6928\n",
      "Epoch: [9/20],  Loss: 7.6660\n",
      "Epoch: [9/20],  Loss: 7.7066\n",
      "Epoch: [9/20],  Loss: 7.7200\n",
      "Epoch: [9/20],  Loss: 7.7053\n",
      "Epoch: [9/20],  Loss: 7.6731\n",
      "Epoch: [10/20],  Loss: 7.6981\n",
      "Epoch: [10/20],  Loss: 7.6870\n",
      "Epoch: [10/20],  Loss: 7.7209\n",
      "Epoch: [10/20],  Loss: 7.7190\n",
      "Epoch: [10/20],  Loss: 7.7174\n",
      "Epoch: [10/20],  Loss: 7.6985\n",
      "Epoch: [10/20],  Loss: 7.7118\n",
      "Epoch: [11/20],  Loss: 7.7108\n",
      "Epoch: [11/20],  Loss: 7.7056\n",
      "Epoch: [11/20],  Loss: 7.7270\n",
      "Epoch: [11/20],  Loss: 7.7216\n",
      "Epoch: [11/20],  Loss: 7.6909\n",
      "Epoch: [11/20],  Loss: 7.6966\n",
      "Epoch: [11/20],  Loss: 7.6937\n",
      "Epoch: [12/20],  Loss: 7.7075\n",
      "Epoch: [12/20],  Loss: 7.6871\n",
      "Epoch: [12/20],  Loss: 7.6794\n",
      "Epoch: [12/20],  Loss: 7.6829\n",
      "Epoch: [12/20],  Loss: 7.6806\n",
      "Epoch: [12/20],  Loss: 7.6716\n",
      "Epoch: [12/20],  Loss: 7.6561\n",
      "Epoch: [13/20],  Loss: 7.6723\n",
      "Epoch: [13/20],  Loss: 7.6570\n",
      "Epoch: [13/20],  Loss: 7.6446\n",
      "Epoch: [13/20],  Loss: 7.6361\n",
      "Epoch: [13/20],  Loss: 7.6657\n",
      "Epoch: [13/20],  Loss: 7.6625\n",
      "Epoch: [13/20],  Loss: 7.6481\n",
      "Epoch: [14/20],  Loss: 7.6375\n",
      "Epoch: [14/20],  Loss: 7.6687\n",
      "Epoch: [14/20],  Loss: 7.6408\n",
      "Epoch: [14/20],  Loss: 7.6316\n",
      "Epoch: [14/20],  Loss: 7.6295\n",
      "Epoch: [14/20],  Loss: 7.6530\n",
      "Epoch: [14/20],  Loss: 7.6498\n",
      "Epoch: [15/20],  Loss: 7.6497\n",
      "Epoch: [15/20],  Loss: 7.6526\n",
      "Epoch: [15/20],  Loss: 7.6586\n",
      "Epoch: [15/20],  Loss: 7.6501\n",
      "Epoch: [15/20],  Loss: 7.6538\n",
      "Epoch: [15/20],  Loss: 7.6589\n",
      "Epoch: [15/20],  Loss: 7.6546\n",
      "Epoch: [16/20],  Loss: 7.6117\n",
      "Epoch: [16/20],  Loss: 7.6098\n",
      "Epoch: [16/20],  Loss: 7.6064\n",
      "Epoch: [16/20],  Loss: 7.5954\n",
      "Epoch: [16/20],  Loss: 7.6007\n",
      "Epoch: [16/20],  Loss: 7.6182\n",
      "Epoch: [16/20],  Loss: 7.6224\n",
      "Epoch: [17/20],  Loss: 7.6100\n",
      "Epoch: [17/20],  Loss: 7.6234\n",
      "Epoch: [17/20],  Loss: 7.6156\n",
      "Epoch: [17/20],  Loss: 7.6107\n",
      "Epoch: [17/20],  Loss: 7.5895\n",
      "Epoch: [17/20],  Loss: 7.5977\n",
      "Epoch: [17/20],  Loss: 7.5946\n",
      "Epoch: [18/20],  Loss: 7.6202\n",
      "Epoch: [18/20],  Loss: 7.6290\n",
      "Epoch: [18/20],  Loss: 7.6417\n",
      "Epoch: [18/20],  Loss: 7.6394\n",
      "Epoch: [18/20],  Loss: 7.6306\n",
      "Epoch: [18/20],  Loss: 7.6247\n",
      "Epoch: [18/20],  Loss: 7.6412\n",
      "Epoch: [19/20],  Loss: 7.6569\n",
      "Epoch: [19/20],  Loss: 7.6403\n",
      "Epoch: [19/20],  Loss: 7.6367\n",
      "Epoch: [19/20],  Loss: 7.6366\n",
      "Epoch: [19/20],  Loss: 7.6470\n",
      "Epoch: [19/20],  Loss: 7.6570\n",
      "Epoch: [19/20],  Loss: 7.6639\n",
      "Epoch: [20/20],  Loss: 7.6524\n",
      "Epoch: [20/20],  Loss: 7.6347\n",
      "Epoch: [20/20],  Loss: 7.6264\n",
      "Epoch: [20/20],  Loss: 7.6292\n",
      "Epoch: [20/20],  Loss: 7.6445\n",
      "Epoch: [20/20],  Loss: 7.6428\n",
      "Epoch: [20/20],  Loss: 7.6534\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "num_epochs = 20\n",
    "\n",
    "\n",
    "model = LogisticRegression(4, 2)\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "losses = []\n",
    "for epoch in range(1, num_epochs + 1):        \n",
    "    for i, (x, y) in enumerate(train_loader): \n",
    "\n",
    "        x_train = Variable(x)\n",
    "        y_train = Variable(y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.cpu().data[0])\n",
    "        loss = np.mean(losses)\n",
    "\n",
    "        if (i+1) % 1000 == 0:\n",
    "            print ('Epoch: [%d/%d],  Loss: %.4f' \n",
    "                   % (epoch, num_epochs, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18790469, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = pd.DataFrame()\n",
    "test_pred['click_id'] = test_df['click_id'].astype('int')\n",
    "test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>click_id</th>\n",
       "      <th>is_attributed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   click_id  is_attributed\n",
       "0         0              0\n",
       "1         1              0\n",
       "2         2              0\n",
       "3         3              0\n",
       "4         4              0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "predicted = []\n",
    "\n",
    "for x in test_loader:\n",
    "    x = Variable(x)\n",
    "    outputs = model(x)\n",
    "    _, p = torch.max(outputs.data, 1)\n",
    "    predicted.extend(p)\n",
    "test_pred['is_attributed'] = predicted\n",
    "test_pred.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4999969949123867"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predicted = []\n",
    "\n",
    "for x, y_train in train_loader:\n",
    "    x = Variable(x)\n",
    "    outputs = model(x)\n",
    "    _, p = torch.max(outputs.data, 1)\n",
    "    train_predicted.extend(p)\n",
    "train_pred = pd.DataFrame()\n",
    "train_pred['is_attributed'] = train_predicted\n",
    "train_true = train_df['is_attributed']\n",
    "\n",
    "# calculate the ROC AUC\n",
    "# true postive vs false postitive\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# numpy array as the inputs\n",
    "roc_auc_score(train_true.values, train_pred.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# def get_accuracy(data, predicted):\n",
    "#     one_count = 0\n",
    "#     five_count = 0\n",
    "#     for y_train in data:\n",
    "#         predictions = predicted[i]\n",
    "#         label = y_train\n",
    "#         one_count += label == predictions[0]\n",
    "#         five_count += label in predictions\n",
    "#     return float(one_count) / len(predicted), float(five_count) / len(predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_accuracy(train_loader, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate ROC AUC - Area under Receiver Operating characteristic curve."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (detection)",
   "language": "python",
   "name": "detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
